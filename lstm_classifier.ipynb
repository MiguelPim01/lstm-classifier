{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "140060c5",
   "metadata": {},
   "source": [
    "# Treinamento de Rede LSTM para classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4275475a",
   "metadata": {},
   "source": [
    "## Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c16aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "import gensim.downloader as gd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8483391d",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b40a89bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_to_embedding(text: str, embedding_model, max_seq_length: int = 100) -> torch.Tensor:\n",
    "    # Remove HTML tags and non-alphanumeric characters\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    \n",
    "    # Convert to lowercase and split into words\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    \n",
    "    # Truncate to max sequence length\n",
    "    words = words[:max_seq_length]\n",
    "    \n",
    "    # Convert words to embeddings, ignoring words not in the embedding model\n",
    "    embds = torch.tensor(np.array([embedding_model[w] for w in words if w in embedding_model]))\n",
    "    \n",
    "    return embds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9f8ff0",
   "metadata": {},
   "source": [
    "## Preparação do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "020a9106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diretório principal: /home/miguel/.cache/kagglehub/datasets/hgultekin/bbcnewsarchive/versions/1\n",
      "- Arquivos e diretórios filhos:\n",
      "\tbbc-news-data.csv\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"hgultekin/bbcnewsarchive\")\n",
    "path = Path(path)\n",
    "\n",
    "print(f\"Diretório principal: {path}\")\n",
    "\n",
    "print(\"- Arquivos e diretórios filhos:\")\n",
    "for file in path.iterdir():\n",
    "    print(f\"\\t{file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ce0feb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>filename</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>politics</td>\n",
       "      <td>226.txt</td>\n",
       "      <td>Tories unveil quango blitz plans</td>\n",
       "      <td>Plans to abolish 162 quangos have been unveil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>258.txt</td>\n",
       "      <td>No jail for singer Courtney Love</td>\n",
       "      <td>Singer Courtney Love has been spared jail for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits</td>\n",
       "      <td>British Airways has blamed high fuel prices f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>politics</td>\n",
       "      <td>279.txt</td>\n",
       "      <td>Amnesty chief laments war failure</td>\n",
       "      <td>The lack of public outrage about the war on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>sport</td>\n",
       "      <td>155.txt</td>\n",
       "      <td>Benitez joy as Reds take control</td>\n",
       "      <td>Liverpool boss Rafael Benitez was satisfied a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           category filename                              title  \\\n",
       "1121       politics  226.txt   Tories unveil quango blitz plans   \n",
       "767   entertainment  258.txt   No jail for singer Courtney Love   \n",
       "3          business  004.txt  High fuel prices hit BA's profits   \n",
       "1174       politics  279.txt  Amnesty chief laments war failure   \n",
       "1467          sport  155.txt   Benitez joy as Reds take control   \n",
       "\n",
       "                                                content  \n",
       "1121   Plans to abolish 162 quangos have been unveil...  \n",
       "767    Singer Courtney Love has been spared jail for...  \n",
       "3      British Airways has blamed high fuel prices f...  \n",
       "1174   The lack of public outrage about the war on t...  \n",
       "1467   Liverpool boss Rafael Benitez was satisfied a...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(path / 'bbc-news-data.csv', sep='\\t')\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c10ee36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>filename</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>tech</td>\n",
       "      <td>213.txt</td>\n",
       "      <td>Search sites get closer to users</td>\n",
       "      <td>Search sites want to get to know you better. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>politics</td>\n",
       "      <td>201.txt</td>\n",
       "      <td>Howard rejects BNP's claim</td>\n",
       "      <td>Tory leader Michael Howard has dismissed clai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>tech</td>\n",
       "      <td>373.txt</td>\n",
       "      <td>Software watching while you work</td>\n",
       "      <td>Software that can not only monitor every keys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>business</td>\n",
       "      <td>241.txt</td>\n",
       "      <td>G7 backs Africa debt relief plan</td>\n",
       "      <td>G7 finance ministers have backed plans to wri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>business</td>\n",
       "      <td>365.txt</td>\n",
       "      <td>Nasdaq planning $100m-share sale</td>\n",
       "      <td>The owner of the technology-dominated Nasdaq ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category filename                             title  \\\n",
       "2036      tech  213.txt  Search sites get closer to users   \n",
       "1096  politics  201.txt        Howard rejects BNP's claim   \n",
       "2196      tech  373.txt  Software watching while you work   \n",
       "240   business  241.txt  G7 backs Africa debt relief plan   \n",
       "364   business  365.txt  Nasdaq planning $100m-share sale   \n",
       "\n",
       "                                                content  \n",
       "2036   Search sites want to get to know you better. ...  \n",
       "1096   Tory leader Michael Howard has dismissed clai...  \n",
       "2196   Software that can not only monitor every keys...  \n",
       "240    G7 finance ministers have backed plans to wri...  \n",
       "364    The owner of the technology-dominated Nasdaq ...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# APENAS PARA TESTES\n",
    "data = data.sample(frac=0.1)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17963290",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63c5c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_embedding_model = gd.load(\"glove-twitter-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6380a9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: McCririck out of Big Brother show\n",
      "\n",
      "Embeddings shape: torch.Size([6, 50])\n"
     ]
    }
   ],
   "source": [
    "text = data.sample(1)[\"title\"].values[0]\n",
    "\n",
    "embds = preprocess_text_to_embedding(text=text, embedding_model=gensim_embedding_model)\n",
    "\n",
    "print(f\"Texto: {text}\")\n",
    "print(f\"\\nEmbeddings shape: {embds.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8386c8d7",
   "metadata": {},
   "source": [
    "Pré-processando todas as linhas do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c474455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de amostras processadas: 222\n"
     ]
    }
   ],
   "source": [
    "X = [\n",
    "    preprocess_text_to_embedding(\n",
    "        text=t,\n",
    "        embedding_model=gensim_embedding_model\n",
    "    ) for t in data[\"content\"]\n",
    "]\n",
    "\n",
    "print(f\"Total de amostras processadas: {len(X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7aeefc",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ea86b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 2, 4, 0, 0, 2, 0, 1, 2, 3, 0, 0, 2, 0, 0, 4, 3, 3, 1, 2, 4, 3, 0, 1,\n",
       "        3, 4, 4, 1, 4, 1, 3, 1, 3, 4, 2, 2, 2, 3, 3, 4, 2, 4, 1, 3, 4, 3, 1, 1,\n",
       "        4, 2, 0, 2, 2, 2, 3, 4, 4, 3, 4, 2, 3, 0, 4, 1, 2, 0, 0, 0, 4, 1, 2, 4,\n",
       "        3, 1, 3, 1, 0, 3, 2, 2, 2, 4, 1, 2, 4, 3, 1, 3, 4, 4, 4, 3, 3, 1, 1, 3,\n",
       "        4, 4, 2, 3, 4, 1, 3, 4, 4, 4, 2, 0, 4, 2, 3, 2, 1, 1, 3, 0, 3, 3, 3, 3,\n",
       "        1, 1, 3, 3, 3, 0, 0, 4, 4, 1, 4, 2, 4, 1, 0, 3, 1, 1, 0, 2, 4, 3, 3, 4,\n",
       "        3, 1, 1, 1, 3, 0, 4, 4, 1, 1, 4, 4, 3, 1, 1, 3, 2, 0, 3, 4, 0, 2, 2, 3,\n",
       "        1, 1, 3, 1, 2, 1, 2, 4, 1, 3, 3, 2, 2, 1, 1, 2, 3, 4, 0, 1, 0, 2, 1, 4,\n",
       "        0, 0, 1, 1, 3, 4, 3, 1, 2, 2, 2, 0, 2, 0, 0, 3, 4, 2, 3, 2, 4, 1, 1, 4,\n",
       "        3, 1, 4, 3, 2, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "y = encoder.fit_transform(data[\"category\"])\n",
    "y = y.astype(np.int64)\n",
    "y = torch.tensor(y)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baed9ed",
   "metadata": {},
   "source": [
    "## Dataset e Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b01f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "test_ds = TensorDataset(x_test, y_test)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)\n",
    "\n",
    "print(f\"Total de treino: {len(train_ds)}\")\n",
    "print(f\"Total de teste: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cf1328",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5841cdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        hidden_size = 32\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=50,     # embedding size\n",
    "            hidden_size=hidden_size,\n",
    "            bidirectional=False,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def forward(self, sequence):\n",
    "        _, (hidden, cell) = self.lstm(sequence)\n",
    "        \n",
    "        dropped = self.dropout(hidden.squeeze(0))\n",
    "        \n",
    "        prediction = self.fc(dropped)\n",
    "        \n",
    "        return prediction\n",
    "\n",
    "net = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21b42c8",
   "metadata": {},
   "source": [
    "## Treinamento e avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b292e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "history = []\n",
    "n_epochs = 20\n",
    "\n",
    "# repete por um número de épocas\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # epoca de treinamento: itera sobre os batches do conjunto de treino\n",
    "    net.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    running_loss /= len(train_ds)\n",
    "\n",
    "    # avaliação no conjunto de teste\n",
    "    net.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_loss /= len(test_ds)\n",
    "\n",
    "    history.append([running_loss, test_loss])\n",
    "\n",
    "    if epoch % max(1, n_epochs // 20)  == 0:\n",
    "        print(f'[{epoch + 1}] loss: {running_loss:.4f} test loss: {test_loss:.4f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f9f090",
   "metadata": {},
   "source": [
    "Evolução da **função de perda** nos conjuntos de treino e teste ao longo do treinamento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e282929",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = np.array(history)\n",
    "\n",
    "plt.plot(history[:, 0], '-', color='orange', label='train')\n",
    "plt.plot(history[:, 1], '-', color='blue', label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95807556",
   "metadata": {},
   "source": [
    "## Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435c9f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "preds = []\n",
    "\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        cls = np.argmax(outputs, axis=-1)\n",
    "        all_labels += list(labels)\n",
    "        preds += list(cls)\n",
    "\n",
    "print(classification_report(all_labels, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
